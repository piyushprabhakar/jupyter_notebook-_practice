{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upi2EY4L9ei3"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbF2F2miAT4a"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googleapis/langchain-google-alloydb-pg-python/blob/main/samples/langchain_quick_start.ipynb)\n",
        "\n",
        "---\n",
        "# Introduction\n",
        "\n",
        "In this codelab, you'll learn how to create a powerful interactive generative AI application using Retrieval Augmented Generation powered by [AlloyDB for PostgreSQL](https://cloud.google.com/alloydb) and [LangChain](https://www.langchain.com/). We will be creating an application grounded in a [Netflix Movie dataset](https://www.kaggle.com/datasets/shivamb/netflix-shows), allowing you to interact with movie data in exciting new ways."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma6pEng3ypbA"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "* A basic understanding of the Google Cloud Console\n",
        "* Basic skills in command line interface and Google Cloud shell\n",
        "* Basic python knowledge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzDgqJHgysy1"
      },
      "source": [
        "## What you'll learn\n",
        "\n",
        "* How to deploy a AlloyDB for PostgreSQL instance\n",
        "* How to use AlloyDB for PostgreSQL as a VectorStore\n",
        "* How to use AlloyDB for PostgreSQL as a DocumentLoader\n",
        "* How to use AlloyDB for PostgreSQL for ChatHistory storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbcZUjT1yvTq"
      },
      "source": [
        "## What you'll need\n",
        "\n",
        "* A Google Cloud Account and Google Cloud Project\n",
        "* A web browser such as [Chrome](https://www.google.com/chrome/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHdR4fF3vLWA"
      },
      "source": [
        "# Setup and Requirements\n",
        "\n",
        "In the following instructions you will learn to:\n",
        "\n",
        "1. Install required dependencies for our application\n",
        "2. Set up authentication for our project\n",
        "3. Set up a AlloyDB for PostgreSQL Instance\n",
        "4. Import the data used by our application"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy9KqgPQ4GBi"
      },
      "source": [
        "## Install dependencies\n",
        "First you will need to install the dependencies needed to run this demo app."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M_ppDxYf4Gqs",
        "outputId": "449c48d8-f809-47bb-ce22-405d2e994057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-google-alloydb-pg\n",
            "  Downloading langchain_google_alloydb_pg-0.9.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.15)\n",
            "Collecting langchain-google-vertexai\n",
            "  Downloading langchain_google_vertexai-2.0.12-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting google-cloud-alloydb-connector[pg8000]\n",
            "  Downloading google_cloud_alloydb_connector-1.7.0-py2.py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-alloydb-pg) (2.19.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.2.36 in /usr/local/lib/python3.11/dist-packages (from langchain-google-alloydb-pg) (0.3.31)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from langchain-google-alloydb-pg) (1.26.4)\n",
            "Collecting pgvector<1.0.0,>=0.2.5 (from langchain-google-alloydb-pg)\n",
            "  Downloading pgvector-0.3.6-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=2.0.25 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]<3.0.0,>=2.0.25->langchain-google-alloydb-pg) (2.0.37)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Collecting google-cloud-aiplatform<2.0.0,>=1.76.0 (from langchain-google-vertexai)\n",
            "  Downloading google_cloud_aiplatform-1.79.0-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: httpx<0.29.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-vertexai) (0.28.1)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-google-vertexai)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting aiofiles (from google-cloud-alloydb-connector[pg8000])\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: cryptography>=42.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-alloydb-connector[pg8000]) (43.0.3)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.11/dist-packages (from google-cloud-alloydb-connector[pg8000]) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-cloud-alloydb-connector[pg8000]) (4.25.6)\n",
            "Collecting pg8000>=1.31.1 (from google-cloud-alloydb-connector[pg8000])\n",
            "  Downloading pg8000-1.31.2-py3-none-any.whl.metadata (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=42.0.0->google-cloud-alloydb-connector[pg8000]) (1.17.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.76.0->langchain-google-vertexai) (2.19.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.76.0->langchain-google-vertexai) (1.25.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.76.0->langchain-google-vertexai) (24.2)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.76.0->langchain-google-vertexai) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.76.0->langchain-google-vertexai) (1.14.0)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.76.0->langchain-google-vertexai) (2.0.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.76.0->langchain-google-vertexai) (4.12.2)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.76.0->langchain-google-vertexai) (0.16)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth->google-cloud-alloydb-connector[pg8000]) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth->google-cloud-alloydb-connector[pg8000]) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth->google-cloud-alloydb-connector[pg8000]) (4.9)\n",
            "Collecting asyncpg>=0.30.0 (from google-cloud-alloydb-connector[asyncpg]<2.0.0,>=1.2.0->langchain-google-alloydb-pg)\n",
            "  Downloading asyncpg-0.30.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=2.18.2->langchain-google-alloydb-pg) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=2.18.2->langchain-google-alloydb-pg) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=2.18.2->langchain-google-alloydb-pg) (1.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.0->langchain-google-vertexai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.0->langchain-google-vertexai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.0->langchain-google-vertexai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.0->langchain-google-vertexai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29.0,>=0.28.0->langchain-google-vertexai) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.2.36->langchain-google-alloydb-pg) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pg8000>=1.31.1->google-cloud-alloydb-connector[pg8000]) (2.8.2)\n",
            "Collecting scramp>=1.4.5 (from pg8000>=1.31.1->google-cloud-alloydb-connector[pg8000])\n",
            "  Downloading scramp-1.4.5-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3.0.0,>=2.0.25->SQLAlchemy[asyncio]<3.0.0,>=2.0.25->langchain-google-alloydb-pg) (3.1.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=42.0.0->google-cloud-alloydb-connector[pg8000]) (2.22)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.76.0->langchain-google-vertexai) (1.66.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.76.0->langchain-google-vertexai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.76.0->langchain-google-vertexai) (1.62.3)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.76.0->langchain-google-vertexai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.2.36->langchain-google-alloydb-pg) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth->google-cloud-alloydb-connector[pg8000]) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pg8000>=1.31.1->google-cloud-alloydb-connector[pg8000]) (1.17.0)\n",
            "Collecting asn1crypto>=1.5.1 (from scramp>=1.4.5->pg8000>=1.31.1->google-cloud-alloydb-connector[pg8000])\n",
            "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29.0,>=0.28.0->langchain-google-vertexai) (1.3.1)\n",
            "Downloading langchain_google_alloydb_pg-0.9.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_vertexai-2.0.12-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_aiplatform-1.79.0-py2.py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_alloydb_connector-1.7.0-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pg8000-1.31.2-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pgvector-0.3.6-py3-none-any.whl (24 kB)\n",
            "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading asyncpg-0.30.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scramp-1.4.5-py3-none-any.whl (12 kB)\n",
            "Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: asn1crypto, scramp, pgvector, httpx-sse, asyncpg, aiofiles, pg8000, google-cloud-alloydb-connector, langchain-google-alloydb-pg, google-cloud-aiplatform, langchain-google-vertexai\n",
            "  Attempting uninstall: google-cloud-aiplatform\n",
            "    Found existing installation: google-cloud-aiplatform 1.74.0\n",
            "    Uninstalling google-cloud-aiplatform-1.74.0:\n",
            "      Successfully uninstalled google-cloud-aiplatform-1.74.0\n",
            "Successfully installed aiofiles-24.1.0 asn1crypto-1.5.1 asyncpg-0.30.0 google-cloud-aiplatform-1.79.0 google-cloud-alloydb-connector-1.7.0 httpx-sse-0.4.0 langchain-google-alloydb-pg-0.9.1 langchain-google-vertexai-2.0.12 pg8000-1.31.2 pgvector-0.3.6 scramp-1.4.5\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "96b0cd123efb4e6eb8aa78e72a6339bd",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%pip install langchain-google-alloydb-pg langchain langchain-google-vertexai google-cloud-alloydb-connector[pg8000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeUbHclxw7_l"
      },
      "source": [
        "## Authenticate to Google Cloud within Colab\n",
        "In order to access your Google Cloud Project from this notebook, you will need to Authenticate as an IAM user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q9hyqdyEx6l"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCiNGP1Qxd6x"
      },
      "source": [
        "## Connect Your Google Cloud Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLUGlG6UE2CK",
        "outputId": "70ca36aa-f292-4f10-d497-7f5854bdbcd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "# @markdown Please fill in the value below with your GCP project ID and then run the cell.\n",
        "\n",
        "# Please fill in these values.\n",
        "project_id = \"rag-alloydb-poc\"  # @param {type:\"string\"}\n",
        "\n",
        "# Quick input validations.\n",
        "assert project_id, \"⚠️ Please provide a Google Cloud project ID\"\n",
        "\n",
        "# Configure gcloud.\n",
        "!gcloud config set project {project_id}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-oqMC5Ox-ZM"
      },
      "source": [
        "## Enable APIs for AlloyDB and Vertex AI within your project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-bzfFb4A-xK"
      },
      "source": [
        "You will need to enable these APIs in order to create an AlloyDB database and utilize Vertex AI as an embeddings service!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKWrwyfzyTwH",
        "outputId": "ca1544d8-8005-452c-cf40-cb07a721cafb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operation \"operations/acat.p2-53247025137-51e94e90-0fc1-44c9-add0-4c00f03815bf\" finished successfully.\n"
          ]
        }
      ],
      "source": [
        "# enable GCP services\n",
        "!gcloud services enable alloydb.googleapis.com aiplatform.googleapis.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn8g7-wCyZU6"
      },
      "source": [
        "## Set up AlloyDB\n",
        "You will need a Postgres AlloyDB instance for the following stages of this notebook. Please set the following variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q2lc-Po1mPv",
        "outputId": "de4ecc5d-d752-41c2-86eb-e815b2564776"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide a password to be used for 'postgres' database user: postgres\n"
          ]
        }
      ],
      "source": [
        "# @markdown Please fill in the both the Google Cloud region and name of your AlloyDB instance. Once filled in, run the cell.\n",
        "\n",
        "# Please fill in these values.\n",
        "region = \"us-central1\"  # @param {type:\"string\"}\n",
        "cluster_name = \"alloydb-cluster\"  # @param {type:\"string\"}\n",
        "instance_name = \"my-primary\"  # @param {type:\"string\"}\n",
        "database_name = \"langchain\"  # @param {type:\"string\"}\n",
        "password = input(\"Please provide a password to be used for 'postgres' database user: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T616pEOUygYQ"
      },
      "source": [
        "### Create an AlloyDB Instance\n",
        "If you have already created an AlloyDB Cluster and Instance, you can skip these steps and skip to the connectivity section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyZYX4Jo1vfh"
      },
      "source": [
        "> ⏳ - Creating an AlloyDB cluster may take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXI1uUu3y8gc",
        "outputId": "ebcd7b41-f401-4936-938d-814b9f74b64f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operation ID: operation-1738177374307-62cdcf4f3c579-a22c421f-0173bf95\n"
          ]
        }
      ],
      "source": [
        "# Quick input validations.\n",
        "assert region, \"⚠️ Please provide a Google Cloud region\"\n",
        "assert instance_name, \"⚠️ Please provide the name of your instance\"\n",
        "assert database_name, \"⚠️ Please provide the name of your database_name\"\n",
        "\n",
        "# create the AlloyDB Cluster\n",
        "!gcloud beta alloydb clusters create {cluster_name} --password={password} --region={region}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8LkscYH5Vfp"
      },
      "source": [
        "Create an instance attached to our cluster with the following command.\n",
        "> ⏳ - Creating an AlloyDB instance may take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkqQSWoY5Kab"
      },
      "outputs": [],
      "source": [
        "!gcloud beta alloydb instances create {instance_name} --instance-type=PRIMARY --cpu-count=2 --region={region} --cluster={cluster_name}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXsQ1UJv4ZVJ"
      },
      "source": [
        "To connect to your AlloyDB instance from this notebook, you will need to enable public IP on your instance. Alternatively, you can follow [these instructions](https://cloud.google.com/alloydb/docs/connect-external) to connect to an AlloyDB for PostgreSQL instance with Private IP from outside your VPC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPVWsQB04Yyl",
        "outputId": "165e4e89-20ff-464e-811f-6826e6afe52d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;31mERROR:\u001b[0m (gcloud.beta.alloydb.instances.update) INVALID_ARGUMENT: The request was invalid: password complexity flag password.enforce_complexity is required when public IP is enabled\n",
            "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
            "  fieldViolations:\n",
            "  - field: database_flags\n",
            "- '@type': type.googleapis.com/google.rpc.RequestInfo\n",
            "  requestId: 71142019d2448fa0\n"
          ]
        }
      ],
      "source": [
        "!gcloud beta alloydb instances update {instance_name} --region={region} --cluster={cluster_name} --assign-inbound-public-ip=ASSIGN_IPV4\n",
        "#Enable public ID of from UI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjA6AiAzB2Du"
      },
      "source": [
        "Now create a connection pool to connect to our instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsLi0a7FIYjT"
      },
      "outputs": [],
      "source": [
        "from google.cloud.alloydb.connector import Connector, IPTypes\n",
        "import sqlalchemy\n",
        "\n",
        "\n",
        "connection_string = f\"projects/{project_id}/locations/{region}/clusters/{cluster_name}/instances/{instance_name}\"\n",
        "# initialize Connector object\n",
        "connector = Connector()\n",
        "\n",
        "\n",
        "# function to return the database connection\n",
        "def getconn():\n",
        "    conn = connector.connect(\n",
        "        connection_string,\n",
        "        \"pg8000\",\n",
        "        user=\"postgres\",\n",
        "        password=password,\n",
        "        db=\"postgres\",\n",
        "        enable_iam_auth=False,\n",
        "        ip_type=IPTypes.PUBLIC,\n",
        "    )\n",
        "    return conn\n",
        "\n",
        "\n",
        "# create connection pool\n",
        "pool = sqlalchemy.create_engine(\n",
        "    \"postgresql+pg8000://\", creator=getconn, isolation_level=\"AUTOCOMMIT\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_yNN1MnJpTR"
      },
      "source": [
        "### Create a Database\n",
        "\n",
        "Next you will create database to store the data for this application using the connection pool. Enabling public IP takes a few minutes, you may get an error that there is no public IP address. Please wait and retry this step if you hit an error!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPE6tt5eJqhq"
      },
      "outputs": [],
      "source": [
        "with pool.connect() as db_conn:\n",
        "    db_conn.execute(sqlalchemy.text(f\"CREATE DATABASE {database_name}\"))\n",
        "connector.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUJ1fK-A-mRd"
      },
      "source": [
        "#### Connect to our New Database\n",
        "\n",
        "Now you will add in a connection function that connects to your new database!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8TSMLes-mRd"
      },
      "outputs": [],
      "source": [
        "from google.cloud.alloydb.connector import Connector, IPTypes\n",
        "import sqlalchemy\n",
        "\n",
        "\n",
        "connection_string = f\"projects/{project_id}/locations/{region}/clusters/{cluster_name}/instances/{instance_name}\"\n",
        "# initialize Connector object\n",
        "connector = Connector()\n",
        "\n",
        "\n",
        "# function to return the database connection\n",
        "def getconn():\n",
        "    conn = connector.connect(\n",
        "        connection_string,\n",
        "        \"pg8000\",\n",
        "        user=\"postgres\",\n",
        "        password=password,\n",
        "        db=database_name,\n",
        "        enable_iam_auth=False,\n",
        "        ip_type=IPTypes.PUBLIC,\n",
        "    )\n",
        "    return conn\n",
        "\n",
        "\n",
        "# create connection pool\n",
        "pool = sqlalchemy.create_engine(\"postgresql+pg8000://\", creator=getconn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdolCWyatZmG"
      },
      "source": [
        "### Import data to your database\n",
        "\n",
        "Now that you have your database, you will need to import data! We will be using a [Netflix Dataset from Kaggle](https://www.kaggle.com/datasets/shivamb/netflix-shows). Here is what the data looks like:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36-FBKzJ-tLa"
      },
      "source": [
        "| show_id | type    | title                | director         | cast                                                                                                                                                  | country       | date_added        | release_year | rating | duration  | listed_in                                    | description                                                                                                                                                                           |\n",
        "|---------|---------|----------------------|------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|-------------------|--------------|--------|-----------|----------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| s1      | Movie   | Dick Johnson Is Dead | Kirsten Johnson  |                                                                                                                                                        | United States | September 25, 2021 | 2020         | PG-13  | 90 min    | Documentaries                                | As her father nears the end of his life, filmmaker Kirsten Johnson stages his death in inventive and comical ways to help them both face the inevitable.                              |\n",
        "| s2      | TV Show | Blood & Water        |                  | Ama Qamata, Khosi Ngema, Gail Mabalane, Thabang Molaba, Dillon Windvogel, Natasha Thahane, Arno Greeff, Xolile Tshabalala, Getmore Sithole, Cindy Mahlangu, Ryle De Morny, Greteli Fincham, Sello Maake Ka-Ncube, Odwa Gwanya, Mekaila Mathys, Sandi Schultz, Duane Williams, Shamilla Miller, Patrick Mofokeng | South Africa  | September 24, 2021 | 2021         | TV-MA  | 2 Seasons | International TV Shows, TV Dramas, TV Mysteries | After crossing paths at a party, a Cape Town teen sets out to prove whether a private-school swimming star is her sister who was abducted at birth.                                   |\n",
        "| s3      | TV Show | Ganglands            | Julien Leclercq  | Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabiha Akkari, Sofia Lesaffre, Salim Kechiouche, Noureddine Farihi, Geert Van Rampelberg, Bakary Diombera                                   |               | September 24, 2021 | 2021         | TV-MA  | 1 Season  | Crime TV Shows, International TV Shows, TV Action & Adventure | To protect his family from a powerful drug lord, skilled thief Mehdi and his expert team of robbers are pulled into a violent and deadly turf war.                                     |\n",
        "| s4      | TV Show | Jailbirds New Orleans |                  |                                                                                                                                                        |               | September 24, 2021 | 2021         | TV-MA  | 1 Season  | Docuseries, Reality TV                        | Feuds, flirtations and toilet talk go down among the incarcerated women at the Orleans Justice Center in New Orleans on this gritty reality series.                                   |\n",
        "| s5      | TV Show | Kota Factory         |                  | Mayur More, Jitendra Kumar, Ranjan Raj, Alam Khan, Ahsaas Channa, Revathi Pillai, Urvi Singh, Arun Kumar                                                 | India        | September 24, 2021 | 2021         | TV-MA  | 2 Seasons | International TV Shows, Romantic TV Shows, TV Comedies | In a city of coaching centers known to train India’s finest collegiate minds, an earnest but unexceptional student and his friends navigate campus life. |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ2KWsYI_Msa"
      },
      "source": [
        "The following code has been prepared code to help insert the CSV data into your AlloyDB for PostgreSQL database."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dzr-2VZIkvtY"
      },
      "source": [
        "Download the CSV file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KkIQ2zSvQkN",
        "outputId": "4277858d-712e-4cbb-ad09-4ce9a332e42e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying gs://cloud-samples-data/langchain/common/first_five_netflix_titles.csv...\n",
            "/ [0 files][    0.0 B/  2.0 KiB]                                                \r/ [1 files][  2.0 KiB/  2.0 KiB]                                                \r\n",
            "Operation completed over 1 objects/2.0 KiB.                                      \n"
          ]
        }
      ],
      "source": [
        "!gsutil cp gs://cloud-samples-data/langchain/common/first_five_netflix_titles.csv ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFU13dCBlYHh"
      },
      "source": [
        "The download can be verified by the following command or using the \"Files\" tab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQBs10I8vShh",
        "outputId": "bb797534-df1a-48ea-fe38-dac1b8866e98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first_five_netflix_titles.csv  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H7rorG9Ivur"
      },
      "source": [
        "In this next step you will:\n",
        "\n",
        "1. Create the table into store data\n",
        "2. And insert the data from the CSV into the database table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCsM2KXbdYiv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "#netflix_titles\n",
        "create_table_cmd = sqlalchemy.text(\n",
        "    'CREATE TABLE netflix_titles ( \\\n",
        "    show_id VARCHAR, \\\n",
        "    type VARCHAR, \\\n",
        "    title VARCHAR, \\\n",
        "    director VARCHAR, \\\n",
        "    \"cast\" VARCHAR, \\\n",
        "    country VARCHAR, \\\n",
        "    date_added VARCHAR, \\\n",
        "    release_year INTEGER, \\\n",
        "    rating VARCHAR, \\\n",
        "    duration VARCHAR, \\\n",
        "    listed_in VARCHAR, \\\n",
        "    description TEXT \\\n",
        "    )',\n",
        ")\n",
        "\n",
        "netflix_data = \"/content/first_five_netflix_titles.csv\"\n",
        "\n",
        "df = pd.read_csv(netflix_data)\n",
        "insert_data_cmd = sqlalchemy.text(\n",
        "    \"\"\"\n",
        "    INSERT INTO netflix_titles VALUES (:show_id, :type, :title, :director,\n",
        "      :cast, :country, :date_added, :release_year, :rating,\n",
        "      :duration, :listed_in, :description)\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "parameter_map = [\n",
        "    {\n",
        "        \"show_id\": row[\"show_id\"],\n",
        "        \"type\": row[\"type\"],\n",
        "        \"title\": row[\"title\"],\n",
        "        \"director\": row[\"director\"],\n",
        "        \"cast\": row[\"cast\"],\n",
        "        \"country\": row[\"country\"],\n",
        "        \"date_added\": row[\"date_added\"],\n",
        "        \"release_year\": row[\"release_year\"],\n",
        "        \"rating\": row[\"rating\"],\n",
        "        \"duration\": row[\"duration\"],\n",
        "        \"listed_in\": row[\"listed_in\"],\n",
        "        \"description\": row[\"description\"],\n",
        "    }\n",
        "    for index, row in df.iterrows()\n",
        "]\n",
        "\n",
        "with pool.connect() as db_conn:\n",
        "    db_conn.execute(create_table_cmd)\n",
        "    db_conn.execute(\n",
        "        insert_data_cmd,\n",
        "        parameter_map,\n",
        "    )\n",
        "    db_conn.commit()\n",
        "connector.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsGS80H04bDN"
      },
      "source": [
        "## Use case 1: AlloyDB for Postgres as a document loader\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Now that you have data in your database, you are ready to use AlloyDB for PostgreSQL as a document loader. This means you will pull data from the database and load it into memory as documents. These documents can be used to create a vector store."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CQgPON8dwSK"
      },
      "source": [
        "First, create a connection to your AlloyDB for PostgreSQL instance using the `AlloyDBEngine` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrwTsWHMkQ_v"
      },
      "outputs": [],
      "source": [
        "from langchain_google_alloydb_pg import AlloyDBEngine, Column, AlloyDBLoader\n",
        "\n",
        "engine = AlloyDBEngine.from_instance(\n",
        "    project_id=project_id,\n",
        "    instance=instance_name,\n",
        "    region=region,\n",
        "    cluster=cluster_name,\n",
        "    database=database_name,\n",
        "    user=\"postgres\",\n",
        "    password=password,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8s-C0P-Oee69"
      },
      "source": [
        "The `AlloyDBLoader` requires an `AlloyDBEngine` object to define the database connection and a `query` to define which data is to be retrieved. The `content_columns` argument can be used to define the columns that will be used as \"content\" in the document object we will later construct. The rest of the columns in that table will become the \"metadata\" associated with the documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SdFJT6Vece1"
      },
      "outputs": [],
      "source": [
        "table_name = \"netflix_titles\"\n",
        "content_columns = [\"title\", \"director\", \"cast\", \"description\"]\n",
        "loader = await AlloyDBLoader.create(\n",
        "    engine=engine,\n",
        "    query=f\"SELECT * FROM {table_name};\",\n",
        "    content_columns=content_columns,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsL-KFrmfuS1"
      },
      "source": [
        "Use method `aload()` to pull documents from out database. You can see the first 5 documents from the database here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4zTx-HLfwmW",
        "outputId": "cd78950d-0195-4365-9c27-1f73b4f6f1c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 5 from the database. 5 Examples:\n",
            "page_content='Dick Johnson Is Dead Kirsten Johnson nan As her father nears the end of his life, filmmaker Kirsten Johnson stages his death in inventive and comical ways to help them both face the inevitable.' metadata={'show_id': 's1', 'type': 'Movie', 'country': 'United States', 'date_added': 'September 25, 2021', 'release_year': 2020, 'rating': 'PG-13', 'duration': '90 min', 'listed_in': 'Documentaries'}\n",
            "page_content='Blood & Water nan Ama Qamata, Khosi Ngema, Gail Mabalane, Thabang Molaba, Dillon Windvogel, Natasha Thahane, Arno Greeff, Xolile Tshabalala, Getmore Sithole, Cindy Mahlangu, Ryle De Morny, Greteli Fincham, Sello Maake Ka-Ncube, Odwa Gwanya, Mekaila Mathys, Sandi Schultz, Duane Williams, Shamilla Miller, Patrick Mofokeng After crossing paths at a party, a Cape Town teen sets out to prove whether a private-school swimming star is her sister who was abducted at birth.' metadata={'show_id': 's2', 'type': 'TV Show', 'country': 'South Africa', 'date_added': 'September 24, 2021', 'release_year': 2021, 'rating': 'TV-MA', 'duration': '2 Seasons', 'listed_in': 'International TV Shows, TV Dramas, TV Mysteries'}\n",
            "page_content='Ganglands Julien Leclercq Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabiha Akkari, Sofia Lesaffre, Salim Kechiouche, Noureddine Farihi, Geert Van Rampelberg, Bakary Diombera To protect his family from a powerful drug lord, skilled thief Mehdi and his expert team of robbers are pulled into a violent and deadly turf war.' metadata={'show_id': 's3', 'type': 'TV Show', 'country': 'nan', 'date_added': 'September 24, 2021', 'release_year': 2021, 'rating': 'TV-MA', 'duration': '1 Season', 'listed_in': 'Crime TV Shows, International TV Shows, TV Action & Adventure'}\n",
            "page_content='Jailbirds New Orleans nan nan Feuds, flirtations and toilet talk go down among the incarcerated women at the Orleans Justice Center in New Orleans on this gritty reality series.' metadata={'show_id': 's4', 'type': 'TV Show', 'country': 'nan', 'date_added': 'September 24, 2021', 'release_year': 2021, 'rating': 'TV-MA', 'duration': '1 Season', 'listed_in': 'Docuseries, Reality TV'}\n",
            "page_content='Kota Factory nan Mayur More, Jitendra Kumar, Ranjan Raj, Alam Khan, Ahsaas Channa, Revathi Pillai, Urvi Singh, Arun Kumar In a city of coaching centers known to train India’s finest collegiate minds, an earnest but unexceptional student and his friends navigate campus life.' metadata={'show_id': 's5', 'type': 'TV Show', 'country': 'India', 'date_added': 'September 24, 2021', 'release_year': 2021, 'rating': 'TV-MA', 'duration': '2 Seasons', 'listed_in': 'International TV Shows, Romantic TV Shows, TV Comedies'}\n"
          ]
        }
      ],
      "source": [
        "documents = await loader.aload()\n",
        "print(f\"Loaded {len(documents)} from the database. 5 Examples:\")\n",
        "for doc in documents[:5]:\n",
        "    print(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xim017o8-mRm"
      },
      "source": [
        "Nice, you just used AlloyDB for Postgres as a document loader!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9uLV3bs4noo"
      },
      "source": [
        "## Use case 2: AlloyDB for PostgreSQL as Vector Store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duVsSeMcgEWl"
      },
      "source": [
        "Now, you will learn how to put all of the documents into a vector store so that you perform a vector search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfH8oQJ945Ko"
      },
      "source": [
        "### Create Your Vector Store table\n",
        "\n",
        "Create a vector store table that can preserve the Document's metadata by using the method `init_vectorstore_table` and defining specific metadata columns. The vector size is required. The example shows the vector size, `768`, that corresponds with the length of the vectors computed by the model our embeddings service uses, Vertex AI's `textembedding-gecko`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_rmjywG47pv"
      },
      "outputs": [],
      "source": [
        "from langchain_google_alloydb_pg import AlloyDBEngine, Column\n",
        "\n",
        "sample_vector_table_name = \"movie_vector_table_samples\"\n",
        "\n",
        "engine = AlloyDBEngine.from_instance(\n",
        "    project_id=project_id,\n",
        "    instance=instance_name,\n",
        "    region=region,\n",
        "    cluster=cluster_name,\n",
        "    database=database_name,\n",
        "    user=\"postgres\",\n",
        "    password=password,\n",
        ")\n",
        "\n",
        "engine.init_vectorstore_table(\n",
        "    sample_vector_table_name,\n",
        "    vector_size=768,\n",
        "    metadata_columns=[\n",
        "        Column(\"show_id\", \"VARCHAR\", nullable=True),\n",
        "        Column(\"type\", \"VARCHAR\", nullable=True),\n",
        "        Column(\"country\", \"VARCHAR\", nullable=True),\n",
        "        Column(\"date_added\", \"VARCHAR\", nullable=True),\n",
        "        Column(\"release_year\", \"INTEGER\", nullable=True),\n",
        "        Column(\"rating\", \"VARCHAR\", nullable=True),\n",
        "        Column(\"duration\", \"VARCHAR\", nullable=True),\n",
        "        Column(\"listed_in\", \"VARCHAR\", nullable=True),\n",
        "    ],\n",
        "    overwrite_existing=True,  # Enabling this will recreate the table if exists.\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG6rwEuJLNIo"
      },
      "source": [
        "### Try inserting the documents into the vector table\n",
        "\n",
        "Next, you will create a `AlloyDBVectorStore` object that connects to the new AlloyDB database table to store the data from the documents. Note that for each row, the embedding service will be called to compute the embeddings to store in the vector table. Pricing details can be found [here](https://cloud.google.com/vertex-ai/pricing)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wo4-7EYCIFF9"
      },
      "outputs": [],
      "source": [
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "from langchain_google_alloydb_pg import AlloyDBVectorStore, AlloyDBEngine\n",
        "\n",
        "# Initialize the embedding service. In this case we are using version 003 of Vertex AI's textembedding-gecko model. In general, it is good practice to specify the model version used.\n",
        "embeddings_service = VertexAIEmbeddings(\n",
        "    model_name=\"textembedding-gecko@003\", project=project_id\n",
        ")\n",
        "\n",
        "engine = AlloyDBEngine.from_instance(\n",
        "    project_id=project_id,\n",
        "    instance=instance_name,\n",
        "    region=region,\n",
        "    cluster=cluster_name,\n",
        "    database=database_name,\n",
        "    user=\"postgres\",\n",
        "    password=password,\n",
        ")\n",
        "\n",
        "vector_store = AlloyDBVectorStore.create_sync(\n",
        "    engine=engine,\n",
        "    embedding_service=embeddings_service,\n",
        "    table_name=sample_vector_table_name,\n",
        "    metadata_columns=[\n",
        "        \"show_id\",\n",
        "        \"type\",\n",
        "        \"country\",\n",
        "        \"date_added\",\n",
        "        \"release_year\",\n",
        "        \"duration\",\n",
        "        \"listed_in\",\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr1rP6KQ-8ag"
      },
      "source": [
        "Now, add the documents data into the vector table. Here is a code example to load the first 5 documents in the list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnbs6hPOfwv9",
        "outputId": "591ce4cc-0f82-4cb2-baf7-c3ee2715fbc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTks8Cy--93B",
        "outputId": "3221a15a-57bf-4750-c9ec-fe984a522981"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['a6f257ed-4119-411e-8798-5476f4c63ccc',\n",
              " '7b2824de-9b8c-4898-ae79-763ecc1b2d62',\n",
              " 'fe5322d6-3193-49b7-a977-22acd71be292',\n",
              " '1fc19be1-7ee4-4fa9-b067-a5b3a5901f7d',\n",
              " '0d0841a2-f142-45f5-80c3-fa67f5e8d34b']"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import uuid\n",
        "\n",
        "docs_to_load = documents[:5]\n",
        "\n",
        "# ! Uncomment the following line to load all 8,800+ documents to the database vector table with calling the embedding service.\n",
        "#docs_to_load = documents\n",
        "\n",
        "ids = [str(uuid.uuid4()) for i in range(len(docs_to_load))]\n",
        "vector_store.add_documents(docs_to_load, ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umWtAjKJWY2d",
        "outputId": "1b9473c9-a122-4aaf-f169-285d3be111c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'rating': 'PG-13'}, page_content='Dick Johnson Is Dead Kirsten Johnson nan As her father nears the end of his life, filmmaker Kirsten Johnson stages his death in inventive and comical ways to help them both face the inevitable.'),\n",
              " Document(metadata={'rating': 'TV-MA'}, page_content='Blood & Water nan Ama Qamata, Khosi Ngema, Gail Mabalane, Thabang Molaba, Dillon Windvogel, Natasha Thahane, Arno Greeff, Xolile Tshabalala, Getmore Sithole, Cindy Mahlangu, Ryle De Morny, Greteli Fincham, Sello Maake Ka-Ncube, Odwa Gwanya, Mekaila Mathys, Sandi Schultz, Duane Williams, Shamilla Miller, Patrick Mofokeng After crossing paths at a party, a Cape Town teen sets out to prove whether a private-school swimming star is her sister who was abducted at birth.'),\n",
              " Document(metadata={'rating': 'TV-MA'}, page_content='Ganglands Julien Leclercq Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabiha Akkari, Sofia Lesaffre, Salim Kechiouche, Noureddine Farihi, Geert Van Rampelberg, Bakary Diombera To protect his family from a powerful drug lord, skilled thief Mehdi and his expert team of robbers are pulled into a violent and deadly turf war.'),\n",
              " Document(metadata={'rating': 'TV-MA'}, page_content='Jailbirds New Orleans nan nan Feuds, flirtations and toilet talk go down among the incarcerated women at the Orleans Justice Center in New Orleans on this gritty reality series.'),\n",
              " Document(metadata={'rating': 'TV-MA'}, page_content='Kota Factory nan Mayur More, Jitendra Kumar, Ranjan Raj, Alam Khan, Ahsaas Channa, Revathi Pillai, Urvi Singh, Arun Kumar In a city of coaching centers known to train India’s finest collegiate minds, an earnest but unexceptional student and his friends navigate campus life.')]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_to_load"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29iztdvfL2BN"
      },
      "source": [
        "### Import the rest of your data into your vector table\n",
        "\n",
        "You don't have to call the embedding service 8,800 times to load all the documents for the demo. Instead, we have prepared a CSV with the all 8,800+ rows with pre-computed embeddings in a CSV file. You can import the CSV using `gsutil`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dE4oQiNyWdC",
        "outputId": "4b300269-9107-43e1-a748-9294ce0b2cba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying gs://cloud-samples-data/langchain/alloydb/netflix_titles_embeddings.csv...\n",
            "- [1 files][ 83.6 MiB/ 83.6 MiB]                                                \n",
            "Operation completed over 1 objects/83.6 MiB.                                     \n"
          ]
        }
      ],
      "source": [
        "!gsutil cp gs://cloud-samples-data/langchain/alloydb/netflix_titles_embeddings.csv ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1TXnKU_DznX"
      },
      "source": [
        "Use the following code to insert the pregenerated embeddings into your vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PDIRYfUyyVyI"
      },
      "outputs": [],
      "source": [
        "netflix_data = \"/content/netflix_titles_embeddings.csv\"\n",
        "df = pd.read_csv(netflix_data)\n",
        "insert_data_cmd = sqlalchemy.text(\n",
        "    \"\"\"\n",
        "    INSERT INTO movie_vector_table_samples VALUES (:langchain_id, :content, :embedding, :show_id,\n",
        "      :type, :country, :date_added, :release_year, :rating,\n",
        "      :duration, :listed_in, :langchain_metadata)\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "parameter_map = [\n",
        "    {\n",
        "        \"langchain_id\": row[\"langchain_id\"],\n",
        "        \"content\": row[\"content\"],\n",
        "        \"embedding\": row[\"embedding\"],\n",
        "        \"show_id\": row[\"show_id\"],\n",
        "        \"type\": row[\"type\"],\n",
        "        \"country\": row[\"country\"],\n",
        "        \"date_added\": row[\"date_added\"],\n",
        "        \"release_year\": row[\"release_year\"],\n",
        "        \"rating\": row[\"rating\"],\n",
        "        \"duration\": row[\"duration\"],\n",
        "        \"listed_in\": row[\"listed_in\"],\n",
        "        \"langchain_metadata\": row[\"langchain_metadata\"],\n",
        "    }\n",
        "    for index, row in df.iterrows()\n",
        "]\n",
        "\n",
        "with pool.connect() as db_conn:\n",
        "    db_conn.execute(\n",
        "        insert_data_cmd,\n",
        "        parameter_map,\n",
        "    )\n",
        "    db_conn.commit()\n",
        "connector.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZM_OFzZrQEPs"
      },
      "source": [
        "# Use case 3: AlloyDB for PostgreSQL as Chat Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxqIPQtjDquk"
      },
      "source": [
        "Next you will add chat history (called “memory” in the context of LangChain) to our application so the LLM can retain context and information across multiple interactions, leading to more coherent and sophisticated conversations or text generation. You can use AlloyDB for PostgreSQL as “memory” storage in our application so that the LLM can use context from prior conversations to better answer the user’s prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "vyYQILyoEAqg"
      },
      "outputs": [],
      "source": [
        "from langchain_google_alloydb_pg import AlloyDBChatMessageHistory, AlloyDBEngine\n",
        "\n",
        "engine = AlloyDBEngine.from_instance(\n",
        "    project_id=project_id,\n",
        "    instance=instance_name,\n",
        "    region=region,\n",
        "    cluster=cluster_name,\n",
        "    database=database_name,\n",
        "    user=\"postgres\",\n",
        "    password=password,\n",
        ")\n",
        "message_table_name = \"message_store\"\n",
        "\n",
        "engine.init_chat_history_table(table_name=message_table_name)\n",
        "\n",
        "chat_history = AlloyDBChatMessageHistory.create_sync(\n",
        "    engine,\n",
        "    session_id=\"my-test-session\",\n",
        "    table_name=message_table_name,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yuXYLTCl2K1"
      },
      "source": [
        "Here is an example of how you would add a user message and how you would add an AI message."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDVoTWZal0ZF",
        "outputId": "75212c5c-d35d-4a81-cba9-a896b600b5f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content=\"Hello there. I'm a model and am happy to help!\", additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "chat_history.add_user_message(\"Hi!\")\n",
        "chat_history.add_ai_message(\"Hello there. I'm a model and am happy to help!\")\n",
        "\n",
        "chat_history.messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0O9mta8RQ0v"
      },
      "source": [
        "## Conversational RAG Chain backed by AlloyDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2OxF3JoNA7J"
      },
      "source": [
        "Try using all 3 integrations with the `ConversationalRetrievalChain`.\n",
        "\n",
        "You will build a chatbot that can answer movie related questions based on the vector search results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "9ukjOO-sNQ8_"
      },
      "outputs": [],
      "source": [
        "from langchain_google_vertexai import VertexAIEmbeddings, VertexAI\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationSummaryBufferMemory\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_google_alloydb_pg import (\n",
        "    AlloyDBEngine,\n",
        "    AlloyDBVectorStore,\n",
        "    AlloyDBChatMessageHistory,\n",
        ")\n",
        "\n",
        "# Intialize the embedding service\n",
        "embeddings_service = VertexAIEmbeddings(\n",
        "    model_name=\"textembedding-gecko@003\", project=project_id\n",
        ")\n",
        "\n",
        "# Intialize the engine\n",
        "engine = AlloyDBEngine.from_instance(\n",
        "    project_id=project_id,\n",
        "    instance=instance_name,\n",
        "    region=region,\n",
        "    cluster=cluster_name,\n",
        "    database=database_name,\n",
        "    user=\"postgres\",\n",
        "    password=password,\n",
        ")\n",
        "# Intialize the Vector Store\n",
        "vector_store = AlloyDBVectorStore.create_sync(\n",
        "    engine=engine,\n",
        "    embedding_service=embeddings_service,\n",
        "    table_name=sample_vector_table_name,\n",
        "    metadata_columns=[\n",
        "        \"show_id\",\n",
        "        \"type\",\n",
        "        \"country\",\n",
        "        \"date_added\",\n",
        "        \"release_year\",\n",
        "        \"duration\",\n",
        "        \"listed_in\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Intialize the AlloyDBChatMessageHistory\n",
        "chat_history = AlloyDBChatMessageHistory.create_sync(\n",
        "    engine,\n",
        "    session_id=\"my-test-session\",\n",
        "    table_name=\"message_store\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ytlz9D3LmcU7"
      },
      "source": [
        "Create a prompt for the LLM. Here we can add instructions specific to our application, such as \"Don't make things up\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "LoAHNdrWmW9W"
      },
      "outputs": [],
      "source": [
        "# Prepare some prompt templates for the ConversationalRetrievalChain\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"Use all the information from the context and the conversation history to answer new question. If you see the answer in previous conversation history or the context. \\\n",
        "Answer it with clarifying the source information. If you don't see it in the context or the chat history, just say you \\\n",
        "didn't find the answer in the given data. Don't make things up.\n",
        "\n",
        "Previous conversation history from the questioner. \"Human\" was the user who's asking the new question. \"Assistant\" was you as the assistant:\n",
        "```{chat_history}\n",
        "```\n",
        "\n",
        "Vector search result of the new question:\n",
        "```{context}\n",
        "```\n",
        "\n",
        "New Question:\n",
        "```{question}```\n",
        "\n",
        "Answer:\"\"\",\n",
        "    input_variables=[\"context\", \"question\", \"chat_history\"],\n",
        ")\n",
        "condense_question_prompt_passthrough = PromptTemplate(\n",
        "    template=\"\"\"Repeat the following question:\n",
        "{question}\n",
        "\"\"\",\n",
        "    input_variables=[\"question\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsGe-bW5m0H1"
      },
      "source": [
        "Next, create a retriever from the vector store in order to retrieve similar documents via a vector search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "1nI0xkJamvXt"
      },
      "outputs": [],
      "source": [
        "# Initialize retriever, llm and memory for the chain\n",
        "retriever = vector_store.as_retriever(\n",
        "    search_type=\"mmr\", search_kwargs={\"k\": 5, \"lambda_mult\": 0.8}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3maZ8SLlneYJ"
      },
      "source": [
        "Next, initialize our LLM, in this case we are using Vertex AI's \"gemini-pro\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "VBWhg-ihnnxF"
      },
      "outputs": [],
      "source": [
        "llm = VertexAI(model_name=\"gemini-pro\", project=project_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN8mpXdtnocg"
      },
      "source": [
        "Clear your chat history, so that our application starts without any prior context to other conversations we have had with the application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UkPcEpJno5Y",
        "outputId": "62804ffa-f611-44ba-b68e-d63202f7db25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-b6e34cd98860>:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationSummaryBufferMemory(\n"
          ]
        }
      ],
      "source": [
        "chat_history.clear()\n",
        "\n",
        "memory = ConversationSummaryBufferMemory(\n",
        "    llm=llm,\n",
        "    chat_memory=chat_history,\n",
        "    output_key=\"answer\",\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDAT2koSn8Mz"
      },
      "source": [
        "Now, create a conversational retrieval chain. This will allow the LLM to use chat history in it's responses, meaning we can ask it follow up questions to our questions instead of having to start from scratch after each inquiry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Fu8fKdEn8h8",
        "outputId": "5c58f118-71ab-41f3-a586-cc9e81fcb4f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-8710e06fe420>:13: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  ans = rag_chain({\"question\": q, \"chat_history\": chat_history})[\"answer\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What movie was Brad Pitt in?\n",
            "Answer: Brad Pitt has acted in several movies, including Inglourious Basterds, By the Sea, Killing Them Softly, and Babel. \n",
            "\n",
            "Question: How about Jonny Depp?\n",
            "Answer: Johnny Depp has acted in many movies, including Charlie and the Chocolate Factory, The Rum Diary, The Imaginarium of Doctor Parnassus, and What's Eating Gilbert Grape. This information is based on the search results you provided. \n",
            "\n",
            "\n",
            "Question: Are there movies about animals?\n",
            "Answer: Yes, there are many movies about animals. Some examples include:\n",
            "\n",
            "* **Open Season** (2006): A domesticated grizzly bear finds himself relocated to the wild and must learn to survive with the help of a clumsy deer.\n",
            "* **DreamWorks Holiday Classics** (2010): A collection of four holiday specials featuring Shrek, Donkey, Hiccup, Toothless, and the animals from Madagascar.\n",
            "* **Animals on the Loose: A You vs. Wild Movie** (2020): Bear Grylls must track down escaped animals and secure their habitat. \n",
            "* **The Animal People** (2017): A documentary about animal rights protesters who are labeled terrorists by big business and law enforcement. \n",
            "\n",
            "I found this information in the search results you provided.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='What movie was Brad Pitt in?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='Brad Pitt has acted in several movies, including Inglourious Basterds, By the Sea, Killing Them Softly, and Babel. ', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='How about Jonny Depp?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content=\"Johnny Depp has acted in many movies, including Charlie and the Chocolate Factory, The Rum Diary, The Imaginarium of Doctor Parnassus, and What's Eating Gilbert Grape. This information is based on the search results you provided. \\n\", additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='Are there movies about animals?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='Yes, there are many movies about animals. Some examples include:\\n\\n* **Open Season** (2006): A domesticated grizzly bear finds himself relocated to the wild and must learn to survive with the help of a clumsy deer.\\n* **DreamWorks Holiday Classics** (2010): A collection of four holiday specials featuring Shrek, Donkey, Hiccup, Toothless, and the animals from Madagascar.\\n* **Animals on the Loose: A You vs. Wild Movie** (2020): Bear Grylls must track down escaped animals and secure their habitat. \\n* **The Animal People** (2017): A documentary about animal rights protesters who are labeled terrorists by big business and law enforcement. \\n\\nI found this information in the search results you provided.', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# create the ConversationalRetrievalChain\n",
        "rag_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    verbose=False,\n",
        "    memory=memory,\n",
        "    condense_question_prompt=condense_question_prompt_passthrough,\n",
        "    combine_docs_chain_kwargs={\"prompt\": prompt},\n",
        ")\n",
        "\n",
        "# ask some questions\n",
        "q = \"What movie was Brad Pitt in?\"\n",
        "ans = rag_chain({\"question\": q, \"chat_history\": chat_history})[\"answer\"]\n",
        "print(f\"Question: {q}\\nAnswer: {ans}\\n\")\n",
        "\n",
        "q = \"How about Jonny Depp?\"\n",
        "ans = rag_chain({\"question\": q, \"chat_history\": chat_history})[\"answer\"]\n",
        "print(f\"Question: {q}\\nAnswer: {ans}\\n\")\n",
        "\n",
        "q = \"Are there movies about animals?\"\n",
        "ans = rag_chain({\"question\": q, \"chat_history\": chat_history})[\"answer\"]\n",
        "print(f\"Question: {q}\\nAnswer: {ans}\\n\")\n",
        "\n",
        "# browser the chat history\n",
        "chat_history.messages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history.clear()"
      ],
      "metadata": {
        "id": "5BeNnCPw2tcN"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"in which year My Little Pony was released?\"\n",
        "ans = rag_chain({\"question\": q, \"chat_history\": chat_history})[\"answer\"]\n",
        "print(f\"Question: {q}\\nAnswer: {ans}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYjDFmBb_KnM",
        "outputId": "a32b0d57-caea-423d-d654-b1c89ef6d989"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: in which year My Little Pony was released?\n",
            "Answer: I didn't find the answer in the given data. I only see that \"My Little Pony\" series has multiple movies but don't know which was first made and released. Is that information in previous questions and their answers or the context? If so,  let me know in which response that information appeared so I can look it up for you and give a more precise answer! \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"what is the story of My Little Pony\"\n",
        "ans = rag_chain({\"question\": q, \"chat_history\": chat_history})[\"answer\"]\n",
        "print(f\"Question: {q}\\nAnswer: {ans}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxgidGjo_wtX",
        "outputId": "190f7a8c-49ce-4cb6-f146-76b3b6a486e3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: what is the story of My Little Pony\n",
            "Answer: The \"My Little Pony\" franchise includes a number of animated series. Here are the stories of some of them I found in the information provided to me: \n",
            "\n",
            "- My Little Pony: Friendship is Magic: The series follows Twilight Sparkle, a studious unicorn who is sent to Ponyville to learn about friendship. Along with her friends, Applejack, Fluttershy, Pinkie Pie, Rainbow Dash, and Rarity, she learns valuable lessons about friendship and helps others.\n",
            "- My Little Pony: Equestria Girls: This alternate universe series features teenage girls who are also ponies. The girls must learn to balance their human lives with their pony magic as they attend Canterlot High. \n",
            "- My Little Pony: A New Generation: The latest generation of ponies, including Sunny Starscout, Zipp Storm, Izzy Moonbow, Hitch Trailblazer, and Pipp Petals, live in a divided Equestria. Sunny believes that the different pony types should be friends and sets out to bring them together.  \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"is Midnight Mass movie or web series\"\n",
        "ans = rag_chain({\"question\": q, \"chat_history\": chat_history})[\"answer\"]\n",
        "print(f\"Question: {q}\\nAnswer: {ans}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amTFiAYG__4Y",
        "outputId": "8aecd38c-5ddf-408c-ffab-804c122bf19c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: is Midnight Mass movie or web series\n",
            "Answer: I didn't find the answer to your question in the given data. However, based on the vector search results, I can tell you that \"Midnight Mass\" seems to be a web series starring Mike Flanagan, Kate Siegel,  and others.  The synopsis suggests that the series has a religious theme and explores topics like miracles and mysteries.  Would you like me to search for more information about \"Midnight Mass\" to confirm if it is a web series instead of a movie? \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"Tell me deatils about The Great British Baking Show\"\n",
        "ans = rag_chain({\"question\": q, \"chat_history\": chat_history})[\"answer\"]\n",
        "print(f\"Question: {q}\\nAnswer: {ans}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0cxKeUAArM_",
        "outputId": "8910af7a-e9e9-4aee-dda1-cbb9c2ea6c40"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Tell me deatils about The Great British Baking Show\n",
            "Answer: ##  The Great British Baking Show: A Delightful Baking Competition  \n",
            "\n",
            "**What is it?**\n",
            "\n",
            "* The Great British Baking Show (also known as The Great British Bake Off) is a popular television baking competition. \n",
            "* Amateur bakers from across the UK compete in weekly challenges showcasing their baking skills. \n",
            "* Judges Paul Hollywood and Prue Leith assess the contestants' efforts, offering constructive feedback and ultimately deciding who stays and who leaves each week. \n",
            "* The winner is crowned Britain's Best Amateur Baker.\n",
            "\n",
            "**Where did it originate?**\n",
            "\n",
            "* The first episode was aired in 2010, quickly gaining immense popularity in the UK. \n",
            "* Its international success led to numerous adaptations around the world, including The Great American Baking Show in the US, The Great Canadian Baking Show, and many more.\n",
            "\n",
            "**What makes it so special?**\n",
            "\n",
            "* **Warm atmosphere:** It's known for its warm and friendly atmosphere, where contestants support and encourage each other throughout the competition. \n",
            "* **Celebrating diversity:** Bakers of all ages and backgrounds come together, sharing their cultural heritage through baking. \n",
            "* **High production value:** The meticulously filmed preparation process is a visual treat. \n",
            "* **Focus on learning:** Viewers enjoy seeing the baking techniques, understanding different ingredients, and picking up valuable tips for their own baking ventures. \n",
            "* **Humor & entertainment:** The witty commentary of hosts Matt Lucas and Noel Fielding, coupled with the occasional baking disasters, provides humor and light entertainment.\n",
            "\n",
            "**Additional facts:**\n",
            "\n",
            "* You'll be delighted with multiple variations like The Great British Baking Show: The Beginnings, Holidays, and Masterclass, offering different experiences and focusing on festive treats, baking basics, and professional techniques respectively.\n",
            "\n",
            "Do you wish to delve deeper into any particular aspect of The Great British Baking Show, or perhaps explore the different versions? Just tell me what interests you most and I'll gladly assist you!\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}